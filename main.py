# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Txa9ol4nOVUB_i02WawELmXVBr-l2_XP
"""

from google.colab import files

# Upload the kaggle.json file
files.upload()

import os

# Create the .kaggle directory and move the token file
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/

# Set permissions for the Kaggle token
!chmod 600 ~/.kaggle/kaggle.json

!pip install -q kaggle

!kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri

!ls

import zipfile

with zipfile.ZipFile("brain-tumor-classification-mri.zip", 'r') as zip_ref:
    zip_ref.extractall("brain_tumor_dataset")

import os

# List the extracted files
print(os.listdir("brain_tumor_dataset"))

# Import necessary libraries
import os
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import matplotlib.pyplot as plt

# Step 1: Define the Custom Dataset Class
class BrainTumorDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        """
        Args:
            image_dir (str): Path to the dataset directory (e.g., Training or Testing).
            transform (callable, optional): Transformations applied to the images.
        """
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = []
        self.labels = []

        # Gather image paths and their corresponding labels
        categories = os.listdir(image_dir)  # Category folders
        for label, category in enumerate(categories):
            category_path = os.path.join(image_dir, category)
            for img_name in os.listdir(category_path):
                img_path = os.path.join(category_path, img_name)
                if os.path.isfile(img_path):  # Ignore directories
                    self.image_paths.append(img_path)
                    self.labels.append(label)

    def __len__(self):
        """Returns the total number of samples."""
        return len(self.image_paths)

    def __getitem__(self, idx):
        """Retrieves an image and its label."""
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        # Load the image
        image = Image.open(img_path).convert("RGB")

        # Apply transformations if specified
        if self.transform:
            image = self.transform(image)

        return image, label

# Step 2: Define Image Transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),  # Resize to 128x128 pixels
    transforms.ToTensor(),         # Convert image to PyTorch tensor
])

# Step 3: Create Dataset Instances
train_dir = "brain_tumor_dataset/Training"  # Path to training data
test_dir = "brain_tumor_dataset/Testing"    # Path to testing data

train_dataset = BrainTumorDataset(image_dir=train_dir, transform=transform)
test_dataset = BrainTumorDataset(image_dir=test_dir, transform=transform)

# Step 4: Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Step 5: Verify Dataset
# Check the number of samples
print("Number of training samples:", len(train_dataset))
print("Number of testing samples:", len(test_dataset))

# Inspect the first sample
image, label = train_dataset[0]
print("Image shape:", image.shape)
print("Label:", label)

# Display the first image
plt.imshow(image.permute(1, 2, 0))  # Convert (C, H, W) to (H, W, C) for display
plt.title(f"Label: {label}")
plt.show()

# Step 6: Iterate Through the DataLoader
for images, labels in train_loader:
    print("Batch of images shape:", images.shape)
    print("Batch of labels shape:", labels.shape)
    break

import torch
from torch.utils.data import random_split

def split_dataset(dataset, split_ratio=0.8):
    """
    Splits a dataset into training and validation subsets.
    Args:
        dataset (Dataset): The dataset to split.
        split_ratio (float): Proportion of the dataset to use for training (default: 0.8).
    Returns:
        train_subset (Subset): Subset for training.
        val_subset (Subset): Subset for validation.
    """
    # Calculate the lengths for training and validation
    train_size = int(split_ratio * len(dataset))
    val_size = len(dataset) - train_size

    # Split the dataset
    train_subset, val_subset = random_split(dataset, [train_size, val_size])
    return train_subset, val_subset

# Example: Splitting the training dataset
train_subset, val_subset = split_dataset(train_dataset, split_ratio=0.8)

# Create DataLoaders for training and validation
train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)

# Verify the split
print(f"Total training samples: {len(train_subset)}")
print(f"Total validation samples: {len(val_subset)}")

# Optional: Inspect a sample from the validation subset
image, label = val_subset[0]
print("Image shape:", image.shape)
print("Label:", label)

import matplotlib.pyplot as plt
from collections import Counter

# Function to calculate class distribution
def calculate_class_distribution(dataset):
    """
    Calculate the distribution of classes in the dataset.
    Args:
        dataset (Dataset): A PyTorch Dataset object.
    Returns:
        dict: A dictionary with class labels as keys and their counts as values.
    """
    labels = [dataset[i][1] for i in range(len(dataset))]  # Extract all labels
    class_counts = Counter(labels)  # Count occurrences of each class
    return class_counts

# Function to visualize class distribution
def plot_class_distribution(class_counts, dataset_name):
    """
    Plot the class distribution as a bar chart.
    Args:
        class_counts (dict): A dictionary with class labels as keys and their counts as values.
        dataset_name (str): Name of the dataset (e.g., Training, Validation, Testing).
    """
    classes = list(class_counts.keys())
    counts = list(class_counts.values())

    plt.bar(classes, counts, color='skyblue')
    plt.xlabel('Class Labels')
    plt.ylabel('Number of Samples')
    plt.title(f'Class Distribution in {dataset_name} Dataset')
    plt.xticks(classes)
    plt.show()

# Calculate and visualize class distribution for all datasets
# Training Dataset
train_class_counts = calculate_class_distribution(train_subset)
plot_class_distribution(train_class_counts, "Training")

# Validation Dataset
val_class_counts = calculate_class_distribution(val_subset)
plot_class_distribution(val_class_counts, "Validation")

# Testing Dataset
test_class_counts = calculate_class_distribution(test_dataset)
plot_class_distribution(test_class_counts, "Testing")

import os
import matplotlib.pyplot as plt
from PIL import Image

def display_images_from_category(image_dir, category, num_images=5):
    """
    Display a set number of images from a specific category for analysis.
    Args:
        image_dir (str): Path to the dataset directory (e.g., Training or Testing).
        category (str): Name of the category (e.g., glioma_tumor).
        num_images (int): Number of images to display.
    """
    category_path = os.path.join(image_dir, category)
    images = os.listdir(category_path)[:num_images]  # Select first `num_images`

    print(f"Category: {category}")
    plt.figure(figsize=(15, 5))

    for i, img_name in enumerate(images):
        img_path = os.path.join(category_path, img_name)
        image = Image.open(img_path)

        # Display image
        plt.subplot(1, num_images, i + 1)
        plt.imshow(image)
        plt.axis("off")
        plt.title(f"{category} - Image {i+1}")

    plt.show()

# Specify dataset directory and categories
dataset_dir = "brain_tumor_dataset/Training"  # Change to Testing if needed
categories = ["glioma_tumor", "meningioma_tumor", "no_tumor", "pituitary_tumor"]

# Display images from each category
for category in categories:
    display_images_from_category(dataset_dir, category, num_images=5)

import os
from PIL import Image
import numpy as np

# Function to verify and standardize the number of channels
def verify_and_fix_channels(image_path, desired_channels=3):
    """
    Ensure all images have the desired number of channels.
    Args:
        image_path (str): Path to the image.
        desired_channels (int): Desired number of channels (1 for grayscale, 3 for RGB).
    Returns:
        Image: Image with the corrected number of channels.
    """
    image = Image.open(image_path)
    if image.mode == 'RGB' and desired_channels == 3:
        return image  # Already correct
    elif image.mode == 'L' and desired_channels == 3:
        return image.convert("RGB")  # Convert grayscale to RGB
    elif image.mode == 'RGB' and desired_channels == 1:
        return image.convert("L")  # Convert RGB to grayscale
    else:
        return image.convert("RGB") if desired_channels == 3 else image.convert("L")

# Function to verify and standardize image dimensions
def verify_and_fix_dimensions(image, desired_size=(256, 256)):
    """
    Ensure all images have the desired dimensions.
    Args:
        image (Image): PIL Image object.
        desired_size (tuple): Desired image size (width, height).
    Returns:
        Image: Resized image.
    """
    if image.size != desired_size:
        return image.resize(desired_size)
    return image

# Function to verify and normalize pixel values
def verify_and_normalize_pixels(image):
    """
    Normalize image pixel values to the range 0-1.
    Args:
        image (Image): PIL Image object.
    Returns:
        np.array: Normalized image array.
    """
    image_array = np.array(image).astype(np.float32)
    return image_array / 255.0  # Normalize to range 0-1

# Process the entire dataset
def process_dataset(dataset_dir, output_dir, desired_channels=3, desired_size=(256, 256)):
    """
    Process the dataset to ensure consistency in channels, dimensions, and pixel normalization.
    Args:
        dataset_dir (str): Path to the dataset directory.
        output_dir (str): Path to save the processed images.
        desired_channels (int): Desired number of channels.
        desired_size (tuple): Desired image dimensions.
    """
    os.makedirs(output_dir, exist_ok=True)
    categories = os.listdir(dataset_dir)

    for category in categories:
        category_path = os.path.join(dataset_dir, category)
        output_category_path = os.path.join(output_dir, category)
        os.makedirs(output_category_path, exist_ok=True)

        print(f"Processing category: {category}")  # Print category being processed

        for img_name in os.listdir(category_path):
            img_path = os.path.join(category_path, img_name)
            output_img_path = os.path.join(output_category_path, img_name)

            try:
                # Load and process the image
                image = verify_and_fix_channels(img_path, desired_channels)
                image = verify_and_fix_dimensions(image, desired_size)
                normalized_image = verify_and_normalize_pixels(image)

                # Save the processed image (normalized as uint8 for storage)
                Image.fromarray((normalized_image * 255).astype(np.uint8)).save(output_img_path)
                print(f"Processed image: {img_name}")  # Print processed image name
            except Exception as e:
                print(f"Error processing image {img_name}: {e}")  # Handle errors gracefully

    print("Dataset processing complete.")

# Example usage
dataset_dir = "brain_tumor_dataset/Training"  # Path to the dataset
output_dir = "processed_brain_tumor_dataset/Training"  # Path to save processed images

process_dataset(dataset_dir, output_dir, desired_channels=3, desired_size=(256, 256))

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageEnhance

# Function to apply Gaussian blur
def apply_gaussian_blur(image, kernel_size=(5, 5)):
    """
    Apply Gaussian blur to reduce noise.
    Args:
        image (np.array): Input image.
        kernel_size (tuple): Size of the Gaussian kernel.
    Returns:
        np.array: Blurred image.
    """
    return cv2.GaussianBlur(image, kernel_size, 0)

# Function to normalize intensity
def normalize_intensity(image):
    """
    Normalize pixel intensity values to the range [0, 1].
    Args:
        image (np.array): Input image.
    Returns:
        np.array: Intensity-normalized image.
    """
    return cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)

# Function to apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
def apply_clahe(image, clip_limit=2.0, tile_grid_size=(8, 8)):
    """
    Apply CLAHE for contrast enhancement.
    Args:
        image (np.array): Input image (grayscale).
        clip_limit (float): Threshold for contrast limiting.
        tile_grid_size (tuple): Size of the grid for CLAHE.
    Returns:
        np.array: Image with enhanced contrast.
    """
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    return clahe.apply(image)

# Function to apply Sobel edge detection
def apply_sobel_filter(image, axis='x'):
    """
    Apply Sobel filter for edge detection.
    Args:
        image (np.array): Input image (grayscale).
        axis (str): 'x' for horizontal edges, 'y' for vertical edges.
    Returns:
        np.array: Edge-detected image.
    """
    if axis == 'x':
        return cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
    elif axis == 'y':
        return cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)

# Function to adjust brightness
def adjust_brightness(image, factor=1.5):
    """
    Adjust brightness of the image.
    Args:
        image (PIL.Image): Input image.
        factor (float): Brightness adjustment factor.
    Returns:
        PIL.Image: Brightness-adjusted image.
    """
    enhancer = ImageEnhance.Brightness(image)
    return enhancer.enhance(factor)

# Function to visualize original and processed images
def visualize_comparison(original, processed, title_original="Original", title_processed="Processed"):
    """
    Display the original and processed images side by side.
    Args:
        original (np.array): Original image.
        processed (np.array): Processed image.
        title_original (str): Title for the original image.
        title_processed (str): Title for the processed image.
    """
    plt.figure(figsize=(10, 5))
    # Display original image
    plt.subplot(1, 2, 1)
    plt.imshow(original, cmap='gray')
    plt.title(title_original)
    plt.axis("off")

    # Display processed image
    plt.subplot(1, 2, 2)
    plt.imshow(processed, cmap='gray')
    plt.title(title_processed)
    plt.axis("off")

    plt.show()

# Specify the path to a valid image file
image_path = "brain_tumor_dataset/Training/glioma_tumor/gg (801).jpg"  # Update with a valid file name

# Check the file path validity
print(f"Checking file path: {image_path}")
if not os.path.exists(image_path):
    print(f"Error: Image file not found at {image_path}. Please check the file path.")
    print("Here is the list of files in the specified directory:")
    folder_path = os.path.dirname(image_path)
    if os.path.exists(folder_path):
        print(os.listdir(folder_path))
    else:
        print(f"The directory {folder_path} does not exist.")
    raise FileNotFoundError(f"Image not found at {image_path}. Please correct the path.")

# Load the image in grayscale
original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
if original_image is None:
    raise ValueError(f"Failed to load image. The file might be corrupted: {image_path}")

# Apply preprocessing techniques
gaussian_blur = apply_gaussian_blur(original_image)
normalized_image = normalize_intensity(original_image)
clahe_image = apply_clahe(original_image)
sobel_edges = apply_sobel_filter(original_image)
brightness_adjusted = adjust_brightness(Image.fromarray(original_image), factor=1.5)

# Visualize comparisons
visualize_comparison(original_image, gaussian_blur, "Original", "Gaussian Blur")
visualize_comparison(original_image, normalized_image, "Original", "Intensity Normalized")
visualize_comparison(original_image, clahe_image, "Original", "CLAHE (Contrast Enhanced)")
visualize_comparison(original_image, sobel_edges, "Original", "Sobel Filter (Edges)")
visualize_comparison(original_image, np.array(brightness_adjusted), "Original", "Brightness Adjusted")

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from tqdm import tqdm

# Step 1: Data Loading
class BrainTumorDataset(torch.utils.data.Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_paths = []
        self.labels = []
        self.transform = transform

        # Load images and labels
        categories = os.listdir(image_dir)
        for label, category in enumerate(categories):
            category_path = os.path.join(image_dir, category)
            for img_name in os.listdir(category_path):
                img_path = os.path.join(category_path, img_name)
                self.image_paths.append(img_path)
                self.labels.append(label)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

# Data augmentation and transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]
])

!ls processed_brain_tumor_dataset

from sklearn.model_selection import train_test_split
import shutil

# Paths to original training data
original_training_dir = "processed_brain_tumor_dataset/Training"
validation_dir = "processed_brain_tumor_dataset/Validation"

# Create validation directory if it doesn't exist
os.makedirs(validation_dir, exist_ok=True)

# Split each category into training and validation
for category in os.listdir(original_training_dir):
    category_path = os.path.join(original_training_dir, category)
    images = os.listdir(category_path)

    # Split into training and validation (80% training, 20% validation)
    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)

    # Ensure category folders exist in the validation directory
    validation_category_path = os.path.join(validation_dir, category)
    os.makedirs(validation_category_path, exist_ok=True)

    # Move validation images to the validation directory
    for val_image in val_images:
        shutil.move(os.path.join(category_path, val_image), os.path.join(validation_category_path, val_image))

!ls processed_brain_tumor_dataset

import os
import shutil
from sklearn.model_selection import train_test_split

# Define paths
original_dir = "processed_brain_tumor_dataset/Training"
testing_dir = "processed_brain_tumor_dataset/Testing"
validation_dir = "processed_brain_tumor_dataset/Validation"

# Ensure the testing and validation directories exist
os.makedirs(testing_dir, exist_ok=True)
os.makedirs(validation_dir, exist_ok=True)

# Split each category into training, validation, and testing
for category in os.listdir(original_dir):
    category_path = os.path.join(original_dir, category)
    images = os.listdir(category_path)

    # Split the dataset: 70% Training, 20% Validation, 10% Testing
    train_images, test_images = train_test_split(images, test_size=0.3, random_state=42)
    val_images, test_images = train_test_split(test_images, test_size=0.33, random_state=42)  # 20% validation, 10% testing

    # Create category folders in testing and validation directories
    os.makedirs(os.path.join(testing_dir, category), exist_ok=True)
    os.makedirs(os.path.join(validation_dir, category), exist_ok=True)

    # Move validation images
    for val_image in val_images:
        shutil.move(os.path.join(category_path, val_image), os.path.join(validation_dir, category, val_image))

    # Move testing images
    for test_image in test_images:
        shutil.move(os.path.join(category_path, test_image), os.path.join(testing_dir, category, test_image))

print("Dataset split completed!")

!ls processed_brain_tumor_dataset/Testing

train_dataset = BrainTumorDataset("processed_brain_tumor_dataset/Training", transform=transform)
val_dataset = BrainTumorDataset("processed_brain_tumor_dataset/Validation", transform=transform)
test_dataset = BrainTumorDataset("processed_brain_tumor_dataset/Testing", transform=transform)

print(f"Number of training samples: {len(train_dataset)}")
print(f"Number of validation samples: {len(val_dataset)}")
print(f"Number of testing samples: {len(test_dataset)}")

import torch.nn as nn
import torch.optim as optim

# Define the CNN model
class CNN(nn.Module):
    def __init__(self, num_classes=4):  # 4 classes: Glioma, Meningioma, No Tumor, Pituitary
        super(CNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # Conv layer 1
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Conv layer 2
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),  # Flatten the output of the convolutional layers
            nn.Linear(64 * 32 * 32, 128),  # Adjust input size based on image dimensions
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

# Instantiate the model
device = "cuda" if torch.cuda.is_available() else "cpu"
model = CNN(num_classes=4).to(device)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification
optimizer = optim.Adam(model.parameters(), lr=0.001)

from tqdm import tqdm  # For displaying a progress bar

# Training function
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    best_val_accuracy = 0
    training_stats = {"train_loss": [], "val_loss": [], "val_accuracy": []}

    for epoch in range(num_epochs):
        # Training phase
        model.train()
        running_loss = 0
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        train_loss = running_loss / len(train_loader)
        training_stats["train_loss"].append(train_loss)

        # Validation phase
        model.eval()
        val_loss = 0
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_loss /= len(val_loader)
        val_accuracy = correct / total
        training_stats["val_loss"].append(val_loss)
        training_stats["val_accuracy"].append(val_accuracy)

        print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}")

        # Save the best model
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            torch.save(model.state_dict(), "best_model.pth")

    return training_stats

# Prepare DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Train the model
stats = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Evaluate the model on the test dataset
def evaluate_model(model, test_loader):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    model.eval()

    y_true = []
    y_pred = []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    # Compute metrics
    cm = confusion_matrix(y_true, y_pred)
    print("Classification Report:")
    print(classification_report(y_true, y_pred, target_names=["Glioma", "Meningioma", "No Tumor", "Pituitary"]))

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Glioma", "Meningioma", "No Tumor", "Pituitary"], yticklabels=["Glioma", "Meningioma", "No Tumor", "Pituitary"])
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix")
    plt.show()

# Load the best saved model
model.load_state_dict(torch.load("best_model.pth"))

# Prepare the test DataLoader
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Evaluate the model
evaluate_model(model, test_loader)

# Plot training and validation loss/accuracy
def plot_training_metrics(stats):
    epochs = range(1, len(stats["train_loss"]) + 1)

    # Plot Loss
    plt.figure(figsize=(12, 5))
    plt.plot(epochs, stats["train_loss"], label="Train Loss")
    plt.plot(epochs, stats["val_loss"], label="Validation Loss")
    plt.title("Training and Validation Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

    # Plot Accuracy
    plt.figure(figsize=(12, 5))
    plt.plot(epochs, stats["val_accuracy"], label="Validation Accuracy")
    plt.title("Validation Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.show()

# Visualize metrics
plot_training_metrics(stats)

